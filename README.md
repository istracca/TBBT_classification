# Evaluating Parameter-Efficient Fine-Tuning for Character Classification in Dialogue Data: A Case Study on *The Big Bang Theory*

This project investigates the effectiveness of parameter-efficient fine-tuning strategies for speaker classification in dialogue data. We use dialogue excerpts from the TV series *The Big Bang Theory* and compare different fine-tuning techniques on sentence embeddings generated by the [`all-MiniLM-L6-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) SBERT model.

---

## üß† Task Overview

We frame the problem as a multi-class or binary classification task depending on the setting. The goal is to classify the speaker of a given line of dialogue.

### Classification Tasks
- **All-vs-All**: Classify among the 7 main characters.
- **Sheldon vs Penny**
- **Sheldon vs Leonard**

### Loss Functions
- Standard **Cross Entropy**
- **Weighted Cross Entropy** to mitigate class imbalance

### Model Variants
All models share the same classifier head: a single hidden-layer MLP with 128 neurons. We compare three fine-tuning strategies:
- **Frozen SBERT + MLP**: Only the MLP is trained.
- **LoRA**: Low-Rank Adaptation applied to SBERT; same MLP head.
- **Last-Layer Unfreeze**: All SBERT parameters frozen except the last layer; MLP head is trained jointly.

## üéØ Bonus: Character Trajectories over Time

As an additional exploratory task, we analyze how character representations evolve across the 10 seasons:
- Compute **average embeddings** per character per season using the best fine-tuned model (Last-Layer + Weighted Loss).
- Visualize the evolution with **t-SNE** to provide a qualitative view of character development.

---


## üì¶ Dataset

The dialogue data used in this project is sourced from Kaggle:

üîó [The Big Bang Theory TV Show Dataset](https://www.kaggle.com/code/lydia70/big-bang-theory-tv-show)

It contains all character lines from Seasons 1 to 10, along with metadata such as speaker and episode.

The raw CSV file used in this project is stored in:

```
data/raw/1_10_seasons_tbbt.csv
```


## üìÅ Project Structure

This project is organized into the following directories:

-   **`data/`**: Stores raw and processed datasets.
    -   `raw/`: Original, unprocessed data.
    -   `processed/`: SBERT embeddings generated by `01_create_dataset.ipynb` after initial preprocessing, and by `07_compute_finetuned_embeddings.ipynb`.
-   **`notebooks/`**: Contains Jupyter notebooks that outline the project workflow, from data preparation to model evaluation and visualization.
    -   `01_create_dataset.ipynb`: Notebook for initial data loading and processing to create the final dataset used for training.
    -   `02_grid_search_classifier_only.ipynb`: Performs hyperparameter tuning for a classifier-only model. Saves metrics and best models.
    -   `03_grid_search_lora.ipynb`: Performs hyperparameter tuning for a LoRA-based model. Saves metrics and best models.
    -   `04_grid_search_last_layer.ipynb`: Performs hyperparameter tuning for a last-layer fine-tuning model. Saves metrics and best models.
    -   `05_evaluate_best_models.ipynb`: Evaluates the best performing models from each approach on the test set.
    -   `06_create_latex_tables.ipynb`: Generates LaTeX-formatted tables summarizing model performance for reporting.
    -   `07_compute_finetuned_embeddings.ipynb`: Computes embeddings from fine-tuned models for further analysis.
    -   `08_tsne_characters_evolution.ipynb`: Visualizes character embedding evolution over time using t-SNE.
-   **`src/`**: Houses reusable Python modules containing core classes and utility functions.
    -   `my_classes.py`: Defines custom classes used across various notebooks, particularly for model architectures or data handling.
    -   `utils.py`: Contains general utility functions, particularly those for `05_evaluate_best_model`.
    -   `utils_latex.py`: Provides functions specifically for generating and formatting LaTeX output, used in `06_create_latex_tables`.
-   **`models/`**: Stores the trained model weights (`.pt` files) for the best performing configurations from each grid search. Organized by model approach.
    -   `classifier_only/`: Best models from the classifier-only approach.
    -   `lora/`: Best models from the LoRA approach.
    -   `last_layer/`: Best models from the last-layer fine-tuning approach.
-   **`metrics/`**: Contains CSV files with detailed training and evaluation metrics for each hyperparameter combination tested during grid search. Organized by model approach.
    -   `classifier_only/`: Metrics for the classifier-only approach.
    -   `lora/`: Metrics for the LoRA approach.
    -   `last_layer/`: Metrics for the last-layer fine-tuning approach.
-   **`images/`**: Stores generated plots and visualizations from the analysis notebooks.
-   **`requirements.txt`**: Lists all Python dependencies required to run the project.



---

## üöÄ Getting Started

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Prepare the dataset
Make sure the raw data file is available at:

```bash
data/raw/1_10_seasons_tbbt.csv
```

Precomputed embeddings are saved under:

```bash
data/processed/
```

### 3. Run the notebooks
You can follow the analysis step-by-step through the notebooks:

01_create_dataset.ipynb: Preprocessing and dataset creation

02‚Äì04: Grid search for each model type

05: Evaluation of best models

06: Generate LaTeX tables for the paper/report

07‚Äì08: Compute and visualize fine-tuned embeddings with t-SNE

---

## üë§ Author
Iacopo Stracca

Project developed as part of a university course assignment. No license applies.
